# more about thread

Thread is a basic unit of CPU utilization,A simple thread mainly comprises a thread ID , a thread,as well as a register set.It shares the same data section and other operation-system resources .For instance the open files and signals.A traditional process has a single thread of control. If we want to perform more than one  task at the same time ,we must have more threads.However ,today most software applications which run on modern computers must be multithreaded. An application typically is implemented as a separate process with several threads of control.  For example ,a web browser must have one thread to receive data from the network while another thread to display images to the user.   In certain situations ,a single application may be required to perform several tasks.For example,a web server  must have several clients concurrently accessing it. If the web server run as a traditional single-threaded process .This means that it can only process one client at a time ,other clients must be wait for long time for its request to be serviced.If The web-server process is multithreaded, the server can create many threads for clients request.When a request is made ,the server create a new thread to to service the client's request and the server can  listening for another request. This is illustrated in [FIGURE](恐龙书165 )
there are several advantages of multithreaded programming .Multithreading an application means that the application can continue running even if part of it is blocked .This is very useful when you design user interfaces.For example if the user clicks the button which results a time consuming operation. If the application is a single thread, the application can't response to the user until the time consuming operation finished.So if the time consuming is a separate thread ,the application can remains responsive to the user. The second advantage is that process can only share resources through some techniques such as sharing message passing and memory.These must be arranged by the programmer .  However threads share sources and memory by default.The benefit of sharing data and resources is that the applications can have several different threads of activity within the same  address space.The other thing is  scalability. the benefit of multithreading can be grater in a multiprocessor ,where the threads can be running on different processing cores.

However ,When we talk about the multiple threads there are still some programming challenges. The first thing must be that the task  can be devided in to separated sections .Ideally when the tasks can be divided into different parts.This is means that these parts are independent of one another thus these  independent parts can run in parallel.
When we split the task into several parts ,we must make sure that theses parts perform equal work of equal value. Sometimes using a parallel computing may not be the worst cost. When we split the work into different parts ,the data must be able to manipulated to run on different cores.Also we have to make sure that the data dependence.When on task depends on the data from another task.We must make sure that the execution of the task is synchronized to get the data's dependency.Another thing is that when a program running on several cores in parallel.,when we  meet problems in our program. Testing and debugging is more difficult than debug a single-threaded applications.So we have to improve our program skills in C Plus Plus.

One thing that when we use the threads for concurrency is the potential to easily and directly to share the data between the threads you use.So there will be something about the shared data. Imagine for a moment that you are sharing a house with several of your  friends. There is only one kitchen and one bathroom in the  department.Everyone in the house can not use the kitchen and the bathroom at the same time.If your one of your friend in using the kitchen for a long time ,it may make you feel frustrated if you also want to use it at the same time.Furthermore, we all know the frustration of sharing a space and getting halfway through a task only to find that someone has borrowed something we need or changed something from the way we left it. This is the same with threads.When we are using the data shared with different threads.We need to have rules for which data can access which bit of data at when,and how any updates are communicated to the other threads that cares about that data.  Incorrectly using the data may cause concurrency-related bugs.The consequence can make your program output totally wrong results.We must be careful when we use  multi-threads.If all the shared data are read-only ,there is no problem with it ,because  the data is unaffected whether or not another thread is reading the same data.However if the data is shared between threads ,some threads may change the data,there is a lot of potential trouble with the program.It would be nice if we
 have one kind of data structure that if one of the thread is accessing the data ,another thread  that tries to access the data have to wait until the first thread was finished.it’s precisely what you get if you use a synchronization primitive called a mutex (mutual exclusion).Before we access the shared  data structure,we can lock the mutex with the data and when we finished we unlock the data,The Thread Library ensures that once that one thread has locked a specific mutex, if there is another one which want to lock the the same mutex have to wait until that successfully locked the mutex unlocks it. This result can ensure that all threads see a self-consistent view of the shared data ,other threads cannot change the shared data when another thread is using the shared data.The mutex is one of the most general data-protection mechanisms available in C++.It is very important to protect the right data.
